const { Pool } = require('pg');
const fs = require('fs');
const path = require('path');

async function runMigration() {
  console.log('üöÄ Ejecutando migraci√≥n 015: Refresh Tokens');

  // Load .env.local if available (simple parsing)
  try {
    const envPath = path.join(__dirname, '..', '.env.local');
    if (fs.existsSync(envPath)) {
      const envConfig = fs.readFileSync(envPath, 'utf8');
      envConfig.split('\n').forEach(line => {
        const [key, ...values] = line.split('=');
        if (key && values.length > 0) {
          process.env[key.trim()] = values.join('=').trim();
        }
      });
    }
  } catch (e) {
    console.warn('‚ö†Ô∏è No se pudo cargar .env.local localmente');
  }

  const connectionString = process.env.DATABASE_URL;

  if (!connectionString) {
    console.error('‚ùå DATABASE_URL no est√° definida');
    process.exit(1);
  }

  const pool = new Pool({ connectionString });

  try {
    const migrationPath = path.join(__dirname, '..', 'migrations', '015_refresh_tokens.sql');
    const sql = fs.readFileSync(migrationPath, 'utf8');

    console.log('üìÑ Leyendo migraci√≥n desde:', migrationPath);
    console.log('üîß Ejecutando SQL...');

    await pool.query(sql);

    console.log('‚úÖ Migraci√≥n 015 ejecutada exitosamente');
    console.log('üìä Tablas creadas:');
    console.log('  - refresh_tokens');

    // Verificar que las tablas existen
    const checkTables = await pool.query(`
      SELECT table_name
      FROM information_schema.tables
      WHERE table_schema = 'public'
      AND table_name IN ('refresh_tokens')
    `);

    console.log('\nüìã Tablas verificadas:', checkTables.rows.map(r => r.table_name).join(', '));

  } catch (error) {
    console.error('‚ùå Error ejecutando migraci√≥n:', error.message);
    throw error;
  } finally {
    await pool.end();
  }
}

runMigration().catch(console.error);
